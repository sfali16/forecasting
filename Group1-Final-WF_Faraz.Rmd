---
title: "Group1-Final-WF_Faraz.Rmd"
author: "C. Loya, S.F. Ali, R. Lakshminarayana & A. Carriedo"
date: "4/3/2020"
output: 
  pdf_document: null
  toc: yes
  number_sections: true
  toc_depth: 4
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

\tableofcontents 
\newpage

# Clear the work space, load libraries

```{r cleanup, echo=FALSE, include=FALSE}
rm(list = ls())
environment()
library(readxl) # read from excel
library(writexl) # write to excel
library(ggplot2) # make ncie plots 
library(xts) # helpful for making dates for time series as.yearmon(). 
library(forecast) # This has the ARMA function 
library(psych) # nice summary statistics with describe() function
library(tinytex)
library(dplyr) # program to filter and pipe the data in the GGPLOT for the forecasts
library(vars)

library(urca) #  for the unit root test function ur.df

## common function used to track minimum BIC obtained so far
minBIC <<- 1000000
# function used to track and update the min BIC found
isMinBIC<-function(armaModel) {
  if ( armaModel$bic < minBIC )  { 
    print("Lower BIC found " )
    minBIC <<- armaModel$bic
    minARIMA <<- armaModel
    minBIC
  }
}

```

# Program Description 

This is an R Markdown document.  The program tries to improve forecasts for the Small Business credit cards issued by Wells Fargo by considering additional series that might explain the number of small business cards opened in California. 
For each series that we consider, we will do the following:
1.  read from excel file,  
2.  plot the series, 
3.  is the series weakly stationary
  3a.  does the series need to be first differenced (remove trend),
  3b.  does the series need to be logged (make homoskedastic), 
4.  estimate the best ARMA model, 
5.  create the forecasts from the best ARMA model, 
6.  Undo the transformations to report in the business setting. 
# Russell 2000 series
## Load the Russell 2000 small-cap market index data into R

Read the data from the excel file and save as a data.frame.   This excel file needs to be in the R working directory.   Alternatively, you would need to include the path the excel file.  

This data is the monthly adjusted closing price of the Russell-2000 small cap index which tracks small and medium sized publicly traded companies  that have not hit the "macro-cap" status.

```{r Read the data, echo=TRUE }

data_from_excel_rut <- read_excel("RUT_raw_data.xlsx") 
data_from_excel_wf <- read_excel("WF_raw_data.xlsx")

str( data_from_excel_rut )
str( data_from_excel_wf )

```


## Make RUT a monthly time series 

Create the time series data structure for RUT index, displays its structure, reports basic summary values, and plots the time series.  

``` {r make_rut_timeseries,_summarize,_and_plot}

rut_ts <- ts(data_from_excel_rut["RUT Adj Close"], start=c(2002,1),  frequency = 12, names =c("Russell 2000 Index") )


str(rut_ts)

describe(rut_ts)  # function from the psych library 

summary(rut_ts)

autoplot(rut_ts, color = 'red') +
  labs(x = "Observation Date", y = "Russell 2000 Index")

```


##  Plot with ggplot2

1. A general description of the data.
2. A plot of the series.
3. Summary statistics.


```{r  ggplot_rut_data}
df_data_rut <- data.frame(date=as.Date(as.yearmon(time(rut_ts))), Y=as.matrix(rut_ts))
df_data_rut
ggplot(data=df_data_rut, mapping=aes(x=date, y=Russell.2000.Index ))+geom_point()+geom_line(color='red')

```


## Make WF a monthly time series 

Create the time series data structure for WF card opens, displays its structure, reports basic summary values, and plots the time series.  

``` {r make_wf_timeseries,_summarize,_and_plot}
wf_ts <- ts(data_from_excel_wf["New Visa Card Opens"], start=c(2002,1), frequency = 12, names =c("New Cards Issued") )


str(wf_ts)

describe(wf_ts)  # function from the psych library 

summary(wf_ts)

autoplot(wf_ts, color = 'blue') +
  labs(x = "Observation Date", y = "New Cards Issued")

```


##  Plot WF with ggplot2

1. A general description of the data.
2. A plot of the series.
3. Summary statistics.


```{r  ggplot_data}
df_data_wf <- data.frame(date=as.Date(as.yearmon(time(wf_ts))), Y=as.matrix(wf_ts))
df_data_wf
ggplot(data=df_data_wf, mapping=aes(x=date, y=New.Cards.Issued ))+geom_point()+geom_line(color='red')

```


## Is the RUT series weakly stationary? 

  This series isn't  weakly stationary - both the mean and the variance are different as you move along the different axes. 
  This means the series is not weakly stationary.   
  
## Make RUT Series weakly stationary  
Trend is removed by taking the first difference. And remove variance by taking the log 
``` {r plot_the_first_difference}

autoplot( diff(rut_ts), colour = 'red') +
  labs(x = "Observation Date", y = "First Difference")

autoplot( diff(log(rut_ts)), color='blue') + 
  labs(x = "Observation Date", y = "First Difference of Log")

```


Thus we now have have a weakly stationary time series by taking the first difference of the log.

``` {r transform_rut_to_weak_stationarity}

Lrut_ts = log(rut_ts)
acf(Lrut_ts, lag.max = 40, main = "ACF for First Diff of log(RUT)")
pacf(Lrut_ts, lag.max = 40, main = "ACF for First Diff of log(RUT)")

```

## Find best ARMA model for the transformed RUT series
### Check basic ARMA models first
```{r default_arima_models}
ARIMA00_noint<- Arima(Lrut_ts, order = c(0,1,0), include.constant = FALSE , method="ML" )  # BIC=-634.94 <== lowest BIC so far
ARIMA00_noint 
isMinBIC(ARIMA00_noint)
minBIC
ARIMA00<- Arima(Lrut_ts,order = c(0,1,0), include.constant = TRUE, method="ML" ) # BIC = -630.79
isMinBIC(ARIMA00)
ARIMA00
```
### Look at residuals
Check ACF and PCF of the best ARIMA model
``` {r ACF_and_PACF_for_ARIMA00_noint}

acf(resid(ARIMA00_noint), lag.max = 20, main = "ACF for ARIMA00_noint Lrut_ts")

pacf( resid(ARIMA00_noint), lag.max = 20, main = "PACF for ARIMA00_noint Lrus_ts")

```
### Structure at lag 6
This shows strucutre at lag 6, so try that next
```{r arma_lag_6}
minBIC
ARIMA_P6_Q0<- Arima(Lrut_ts, order = c(6,1,0), fixed=c(rep.int(0,5), NA), include.constant = FALSE , method="ML" ) #  BIC=-636.03 <-- best BIC so far
ARIMA_P6_Q0 
isMinBIC(ARIMA_P6_Q0)

ARIMA_P0_Q6 <- Arima(Lrut_ts,order = c(0,1,6), fixed=c(rep.int(0,5), NA), include.constant = FALSE, method="ML" ) # BIC=-635.74 not better than best
isMinBIC(ARIMA_P0_Q6)
ARIMA_P0_Q6
```

### Find residuals on best model so far
```{r resid_AR6}
acf(resid(ARIMA_P6_Q0), lag.max = 20, main = "ACF for ARIMA_P6_Q0 Lrut_ts")

pacf( resid(ARIMA_P6_Q0), lag.max = 20, main = "PACF for ARIMA_P6_Q0 Lrus_ts")
```
## Best ARMA model for RUT
Since no structure is seen, the best ARMA model is an AR(6) model without intercept with BIC=-636.03
```{r report_best_ARMA_RUT}
ARIMA_P6_Q0
```

## Is the WF series weakly stationary? 

  This series isn't  weakly stationary - both the mean and the variance are different as you move along the different axes. 
  
## Make WF Series weakly stationary  
Trend is removed by taking the first difference. And remove variance by taking the log 
``` {r plot_the_first_difference_wf}


autoplot( diff(wf_ts), colour = 'blue') +
  labs(x = "Observation Date", y = "First Difference")

autoplot( diff(log(wf_ts)), color='red') + 
  labs(x = "Observation Date", y = "First Difference of Log")

D4Lwf_ts <- diff(log(wf_ts), lag = 4)
autoplot( D4Lwf_ts, color='red') + 
  labs(x = "Observation Date", y = "Fourth Difference of Log")

D12Lwf_ts <- diff(log(wf_ts), lag=12)
autoplot( D12Lwf_ts, color='red') + 
  labs(x = "Observation Date", y = "Twelvth Difference of Log")

DLwf_ts <- diff(log(wf_ts))
acf(DLwf_ts, lag.max = 25, main = "ACF for First Diff of log(WF)")
pacf(DLwf_ts, lag.max = 25, main = "PACF for First Diff of log(WF)")
```


From the ACF of the first difference of the log it looks lik we have seasonality at lag = 12 / yearly seasonality. and it's possible we have some seasonality at lag 4, 8 as well. Let's take seasonality at lag = 12 first and try to fit ARIMA model



## Find best ARMA model for the transformed RUT series
### Check basic ARMA models first
```{r default_arima_models_wf}

Lwf_ts <- log(wf_ts)

minBIC <<- 10000
ARIMA00_noint<- Arima(Lwf_ts, order = c(0,1,0), seasonal=list(order=c(0,1,0), period=12), include.constant = FALSE , method="ML" )  #  BIC=-191.45
ARIMA00_noint 
isMinBIC(ARIMA00_noint)
minBIC
ARIMA00<- Arima(Lwf_ts,order = c(0,1,0), seasonal=list(order=c(0,1,0), period=12),  include.constant = TRUE, method="ML" ) # BIC=-191.45
isMinBIC(ARIMA00)
ARIMA00
```
###  Look at residuals
Check ACF and PCF of the best ARIMA model
``` {r ACF_and_PACF_for_ARIMA00_noint}

acf(resid(ARIMA00_noint), lag.max = 20, main = "ACF for ARIMA00_noint Lwf_ts")

pacf( resid(ARIMA00_noint), lag.max = 20, main = "PACF for ARIMA00_noint Lwf_ts")

```
### Structure at lag 4
This shows strucutre at lag 4, so try to fit models to that lag next next
```{r arma_lag_4}
minBIC
ARIMA_P4_Q0<- Arima(Lwf_ts, order = c(4,1,0), fixed=c(rep.int(0,3), NA), seasonal=list(order=c(0,1,0), period=12), include.constant = FALSE , method="ML" ) #  best bic so far, BIC=-196.86 and ar4 is significant
ARIMA_P4_Q0 
isMinBIC(ARIMA_P4_Q0)

ARIMA_P0_Q4 <- Arima(Lwf_ts,order = c(0,1,4), fixed=c(rep.int(0,3), NA), include.constant = FALSE, method="ML" ) # BIC=-144.43 not lower than best
isMinBIC(ARIMA_P0_Q4)
ARIMA_P0_Q4
```

### Find residuals on best model so far
```{r resid_wf_AR4}
acf(resid(ARIMA_P4_Q0), lag.max = 20, main = "ACF for ARIMA_P6_Q0 Lrut_ts")

pacf( resid(ARIMA_P4_Q0), lag.max = 20, main = "PACF for ARIMA_P6_Q0 Lrus_ts")
```
## Structure at 12, so let's try that next
```{r arma_lag_12}
minBIC
ARIMA_P4.12_Q0 <- Arima(Lwf_ts, order = c(12,1,0), fixed=c(rep.int(0,3), NA, rep.int(0,7), NA), seasonal=list(order=c(0,1,0), period=12), include.constant = FALSE , method="ML" ) #  BIC=-223.12 best bic so far, ar4 and ar12 is stat significant
ARIMA_P4.12_Q0 
isMinBIC(ARIMA_P4.12_Q0)

ARIMA_P4_Q12 <- Arima(Lwf_ts,order = c(4,1,12), fixed=c(rep.int(0,3), NA, rep.int(0,11), NA), include.constant = FALSE, method="ML" ) # BIC=-201.69 not lower than best
isMinBIC(ARIMA_P4_Q12)
ARIMA_P4_Q12
```
## residuals for AR4.12:
```{r resid_wf_AR4.12}
acf(resid(ARIMA_P4.12_Q0), lag.max = 20, main = "ACF for ARIMA_P4.12_Q0 Lwf_ts")

pacf( resid(ARIMA_P4.12_Q0), lag.max = 20, main = "PACF for ARIMA_P4.12_Q0 Lwf_ts")
```
## Structure at 8
There's still some structure at 8, although it could be random variability, let's try it to be sure
```{r arma_lag_8}
minBIC
ARIMA_P4.8.12_Q0 <- Arima(Lwf_ts, order = c(12,1,0), fixed=c(rep.int(0,3), NA, rep.int(0,3), NA, 0, 0, 0, NA), seasonal=list(order=c(0,1,0), period=12), include.constant = FALSE , method="ML" ) # BIC=-218.19 which is not lower than best so far and ar8 is also not stat sig

ARIMA_P4.8.12_Q0 
isMinBIC(ARIMA_P4.8.12_Q0)

ARIMA_P4.12_Q8 <- Arima(Lwf_ts,order = c(12,1,8), fixed=c(rep.int(0,3), NA, rep.int(0,7), NA, rep(0,7), NA), include.constant = FALSE, method="ML" ) # BIC=-240.03 which is lower than best but MA(8) is not statistically significant
isMinBIC(ARIMA_P4.12_Q8)
ARIMA_P4.12_Q8
```
## Best Model for WF 
Since the structure at 8 is not statistically significiant, the best model for WF new cards issues is an AR(4,12) with a seasonal diff of 12 with BIC of -223


## Significant events with Wells Fargo
There appears to be a general positive trend  until there are a couple large declines caused by significant events <br> 
  1. The 2008 Recession that resulted in a period of consistent decline in new cards that lasted until about 2010; and
  2. In early 2016, there was another sharp decline - perhaps this is when the scandal of fake accounts broke out.   

# Select the best VAR model


```{r VAR_model}
DLrut_ts <- diff(log(rut_ts))
VAR_DATA <-  ts.union( DLwf_ts, DLrut_ts) 

#VAR_DATA <-  ts.union( DLGDP_ts, LFF_ts, DLGOV_ts) 

VARselect( VAR_DATA, lag.max = 12, type="const" )

```

# Estimate the VAR model

```{r Estimate_VAR_model}

VAR_est <- VAR(VAR_DATA, p=1, type = "const", season=12)
VAR_est

summary(VAR_est)

``` 

# Let's make a forecast, save it and plot it 

```{r  make_the_forecasts}
forecasts <- forecast(VAR_est, h = 6, level = c(95))
data_from_excel_wf
plot(forecasts )

best.forecast <- forecasts$forecast$DLwf_ts$mean
best.lower <- forecasts$forecast$DLwf_ts$lower
best.upper <- forecasts$forecast$DLwf_ts$upper

col_names <- as.yearqtr(time(forecasts$forecast$DLwf_ts$mean)) 

df <-  data.frame( as.Date(col_names), best.forecast, best.lower, best.upper)

colnames(df) <- c("Date", "Forecast", "50% Lower", "50% Upper" )

write_xlsx(df, "WF_cards_var_prediction.xlsx")

ggplot(data = df, aes(x = Date, y = as.double(Forecast) )) +
  geom_line( color="blue" ) + 
  geom_line(data = df,  aes(x = Date, y = `50% Lower`), color="red" ) +  
  geom_line(data = df,  aes(x = Date, y = `50% Upper`), color="red" ) +
  geom_line(data=(df_data_wf  %>% filter(date > (as.Date('2010-1-1')))) , mapping=aes(x=date, y=New.Cards.Issued))+
  labs(x = "Date", y = "New Cards Issued")+
  ggtitle("Optimally Selected Model Forecast")
```
